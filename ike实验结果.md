5. Experiment (实验)本节我们将进行实验以回答以下研究问题：与基于梯度的方法相比，IKE 的表现如何？演示（Demonstration）的设计策略如何影响 IKE 的性能？语言模型（LMs）的规模如何影响 IKE 的性能？IKE 能否扩展到拥有数百亿或数千亿参数的大型语言模型上？知识编辑会产生哪些副作用？与其他参数更新方法相比，IKE 是否会产生更多或更少的副作用？5.1 Experimental Setting (实验设置)5.1.1 Baselines (基线模型)遵循以往的知识编辑方法，我们选择 GPT-J (6B) 作为主要的评估骨干网络。对比的基线方法包括：FT (Fine-Tuning): 在描述编辑事实的文本上对基础模型进行微调，不训练新的模型编辑器，使用 Adam 优化器并采用早停策略（Early Stopping）。MEND: MEND (Mitchell et al., 2022a) 通过预训练的超网络（Hyper-network），将更新事实的微调梯度分解为 rank-1 形式来转换梯度。ROME: ROME (Meng et al., 2022a) 学习定位特定 MLP 模块中的事实检索，并通过直接在 MLP 模块中写入新的键值对（Key-Value Pair）来更新知识。PROMPT: 用于探索上下文演示如何影响 IKE 的性能。我们直接使用新事实作为上下文来探测 LMs，即 $\mathcal{P}(y|x,f)$，其中 $f=(x^{*},y^{*})$。5.1.2 Evaluation Setup (评估设置)Models (模型):为了探索 LMs 的规模如何影响上下文知识编辑的有效性，我们在五个不同规模的 GPT 类自回归 Transformer 语言模型上评估了 IKE，参数范围从 1.5B 到 175B：GPT-2 XL (1.5B) (Radford et al., 2019)GPT-NEO (2.7B) (Gao et al., 2021)GPT-J (6B) (Wang and Komatsuzaki, 2021)GPT-NEOX (20B) (Black et al., 2022)OPT (175B) (Zhang et al., 2022)Benchmark (基准数据集):我们主要在 COUNTERFACT (Meng et al., 2022a) 上评估基线。这是一个具有挑战性的基准，适用于 GPT 类因果语言模型，包含难以区分的编辑范围。包含 21,919 条不同关系和实体的记录。每条记录的目标是将知识三元组 $(s^*,r^*,o^c)$ 更改为 $(s^*,r^*,o^*)$。记录包含作为范围内（In-scope）提示的改写提示 $P^P$，以及作为范围外（Out-of-scope）提示的邻域提示 $P^N$（即共享相同关系和原始对象但在主体上不同的三元组）。我们遵循 Meng et al. (2022a) 的做法，使用前 2000 条记录作为测试集，其余记录作为训练集。Metrics (评估指标):知识编辑的性能从三个方面衡量（有效性、泛化性和特异性）：Efficacy (有效性): 通过 Efficacy Score (ES) 和 Efficacy Magnitude (EM) 衡量编辑后目标提示的准确性。$ES = \mathbb{E}[\mathbb{I}[\mathcal{P}(o^{*})>\mathcal{P}(o^{c})]]$$EM = \mathbb{E}[\mathcal{P}(o^{*})-\mathcal{P}(o^{c})]$Generalization (泛化性): 通过 Paraphrase Score (PS) 和 Paraphrase Magnitude (PM) 衡量编辑后改写提示的准确性。Specificity (特异性): 通过 Neighborhood Score (NS) 和 Neighborhood Magnitude (NM) 衡量邻域提示的准确性。$NS = \mathbb{E}[\mathbb{I}[\mathcal{P}(o^{c})>\mathcal{P}(o^{*})]]$$NM = \mathbb{E}[\mathcal{P}(o^{c})-\mathcal{P}(o^{*})]$因为邻域提示 $(s', r^*, o^c)$ 与目标提示共享相同的原始对象，这些事实不应被编辑。我们还遵循 Meng et al. (2022a) 的做法，报告 ES、PS、NS 的调和平均数作为 Score (S)。5.2 Main Results (主要结果)表 2 展示了不同方法的知识编辑结果。Table 2: Knowledge Editing Performance for GPT-J (6B) and OPT (175B) on COUNTERFACT(Score S 为综合得分；ES/EM 为有效性；PS/PM 为泛化性；NS/NM 为特异性)Editing Method#Edited Params#Extra ParamsScore SEfficacy (ES / EM)Generalization (PS / PM)Specificity (NS / NM)GPT-J (6B)FT64M028.799.9 / 98.696.4 / 67.011.9 / -48.6MEND384M896M63.690.4 / 53.953.4 / 14.3-3.3 / 57.6ROME64M256M91.599.4 / 10099.6 / 78.078.5 / 5.0PROMPT0063.399.7 / 80.991.0 / 32.937.9 / -2.8IKE (32 examples)020M89.691.7 / 10095.2 / 64.577.0 / 35.2OPT (175B)PROMPT0058.177.2 / 99.694.1 / 37.432.3 / -7.8IKE (32 examples)020M94.1100 / 92.598.8 / 83.685.1 / 45.5结果发现：所有方法在有效性（Efficacy）上表现良好，ES 分数接近。然而，在泛化性和特异性方面存在显著差异。例如，FT 取得了很高的 ES (99.9) 和 PS (96.4)，但在特异性上表现极差（NS=11.9）。这凸显了在知识编辑中平衡泛化性和特异性的挑战。在基线方法中，ROME 总体表现最好，但这伴随着高计算开销。由于这一限制，它不适用于更急需知识编辑的更大规模 LMs（如 OPT-175B）。IKE 在特异性上表现出色，同时也具有良好的有效性和泛化性。例如，IKE 在 GPT-J 上取得了与 ROME 相当的综合得分（89.6 vs 91.5），且无需修改模型参数。这种计算优势使得在 OPT-175B 这样的大模型上进行知识编辑成为可能，在此模型上 IKE 比 PROMPT 提升了 36.0 分。5.3 Analysis (分析)5.3.1 Ablation on Demonstration (演示的消融研究)Demonstration Numbers (演示数量):表 3 第二部分显示，如果没有演示，PROMPT 表现出过度泛化（低 NS 37.9）。随着演示数量增加（从 4 到 32），IKE 逐渐学会平衡泛化性和特异性，实现了更好的权衡。Demonstration Organization (演示组织):表 3 第三部分显示，移除选择过程（即 Random Selection）导致 NS 得分从 77.0 明显下降到 45.0，表明适当的提示选择的重要性。然而，随机排序（Random Ordering）带来的性能差异可以忽略不计。Demonstration Formatting (演示格式):表 3 第四部分显示：移除 Copy 演示导致性能轻微下降。移除 Update 演示导致泛化性得分（PS）大幅下降，说明它在教导 LMs 修改知识方面起重要作用。移除 Retain 演示导致特异性（NS）急剧下降，NM 得分从 35.2 降至 -47.6。这表明 Retain 演示对于帮助 LMs 识别范围外的事实并保持原始预测至关重要。Table 3: Ablation study on demonstration designing (GPT-J)Editing MethodScore SEfficacy ESGeneralization PSSpecificity NSIKE (32 examples)89.610095.277.0- 4 examples81.599.683.567.5- 8 examples84.210085.671.7- 16 examples87.010091.773.6- random selection70.310095.845.0- random ordering88.910095.475.1- w/o copy88.610096.973.9- w/o update84.410073.883.4- w/o retain28.010099.811.55.3.2 IKE Benefits from Model Scaling (IKE 受益于模型扩展)表 4 显示，IKE 的性能与 LM 的规模呈正相关。最大的 OPT-175B 取得了最强的泛化性和特异性结果。Table 4: The IKE performance on different LMs (1.5B to 175B)ModelsGeneralization (PS / PM)Specificity (NS / NM)GPT-2 XL (1.5B)85.1 / 42.821.0 / 72.0GPT-NEO (2.7B)96.3 / 73.528.0 / 70.7GPT-J (6B)95.2 / 64.577.0 / 35.2GPT-NEOX (20B)97.5 / 78.341.3 / 79.8OPT (175B)98.8 / 83.685.1 / 45.55.3.3 Resilience to Over-Editing (对过度编辑的鲁棒性)我们引入 对比知识评估 (CKA) (Dong et al., 2022) 来更全面地评估过度编辑。我们考察 $\mathcal{P}(o^{*}|s^{*},r^{\prime})$ 的变化，其中 $r'$ 是相似但无关的关系。表 5 显示，虽然所有基线在编辑有效性上表现良好，但在更严格的对比评估下，它们倾向于过度泛化。ROME 的 CKA 得分最低且错误率最高（False Rate = 24.1%），表明其识别范围外提示的能力较差。IKE 对过度编辑的影响较小。Table 5: CKA Evaluation (Over-editing Analysis)MethodCKA Score (↑)False Rate (score < α) (↓)$\alpha=1.0$ / $\alpha=1.1$FT1.819.5% / 0.6%ROME1.724.1% / 0.4%PROMPT2.31.0% / 0.2%IKE2.11.7% / 0.1%5.3.4 Maintenance for Original Knowledge (原始知识的维护)表 6 考察了编辑前后 $\mathcal{P}(o^{c}|s^{*},r)$ 的变化。结果表明所有编辑方法都会导致原始事实概率下降。ROME 几乎遗忘了所有原始事实（Forgetting Rate = 99.3%）。Table 6: Knowledge Forgetting Analysis(Prob. Drop: 编辑前后概率差值; Forgetting Rate: 遗忘比例)MethodProb. Drop (↓)Forgetting Rate (↓)FT7.694.1%ROME7.799.3%PROMPT6.264.1%IKE6.150.5%Appendix C: Time-aware Knowledge Editing (时间感知知识编辑)为了评估编辑中的时间感知知识遗忘（例如：2017年美国总统是 Trump，2021年是 Biden），我们在 TEMPLAMA 数据集的基础上构建了一个基准测试。我们依次注入 $(t_1, s, r, o_{t_1}),..., (t_n, s, r, o_{t_n})$，并探测最旧的事实 $(t_1)$ 是否被遗忘。表 10 显示，ROME 遗忘了几乎所有已注入的事实，记忆率极低（0.08%），表明参数更新可能导致同一 FFN 模块中的冲突。相反，IKE 将这些时间感知事实存储在上下文中，在多轮编辑后仍能记忆旧事实。Table 10: Memorization Ratio for the oldest injected factsMethodMemorization Ratio (↑)ROME0.08%IKE88.0%