# 🚀 IKE 快速开始指南

这是一份简化的运行指南，帮助你快速上手这个项目。

## ⚠️ 开始之前的检查

### 1. 检查你的电脑配置
打开终端，运行以下命令检查GPU：
```bash
nvidia-smi
```

**需要确认**：
- ✅ 显卡显存至少16GB（显示的Memory部分）
- ✅ CUDA已安装（会显示CUDA Version）

如果没有这个命令或报错，说明你的电脑可能不支持GPU运算，需要先安装NVIDIA驱动和CUDA。

### 2. 检查Python版本
```bash
python --version
# 或者
python3 --version
```

**需要确认**：
- ✅ Python版本是3.7或更高（比如Python 3.8、3.9、3.10都可以）

---

## 📝 完整步骤清单

### ✅ 第一步：进入项目目录
```bash
cd /data/chenminghao/code/IKE
```

### ✅ 第二步：安装依赖（只需运行一次）
```bash
# 方式1：使用requirements.txt（推荐）
pip install -r requirements.txt

# 方式2：如果上面的命令失败，可以一个个安装
pip install jsonlines==3.1.0
pip install nltk==3.6.7
pip install numpy==1.22.3
pip install openai==0.25.0
pip install sentence-transformers==2.2.0
pip install spacy==3.2.3
pip install torch==1.11.0
pip install tqdm==4.56.0
pip install transformers==4.24.0
```

**预计时间**：5-15分钟（取决于网络速度）

### ✅ 第三步：下载数据集
```bash
# 下载CounterFact数据集
wget https://rome.baulab.info/data/dsets/counterfact.json
```

**如果wget不能用**，请：
1. 用浏览器打开：https://rome.baulab.info/data/dsets/counterfact.json
2. 保存文件到项目目录，确保文件名是`counterfact.json`

**预计时间**：1-5分钟

### ✅ 第四步：清理数据
```bash
python clean_paraphrase.py
```

**预计时间**：1-2分钟

### ✅ 第五步：运行实验！
```bash
# 运行主实验（使用默认的GPT-J-6B模型）
python icl.py
```

**⚠️ 第一次运行注意事项**：
- 第一次运行会自动下载模型（大约6GB），需要等待10-30分钟
- 下载后的模型会保存在本地，下次运行就快了
- 程序会每处理10个样本就输出一次进度
- 处理完2000个样本大约需要几个小时

---

## 🎯 快速测试（推荐新手先运行）

如果你想先快速测试一下环境是否正常，可以使用更小的模型：

```bash
# 使用较小的GPT-2-XL模型测试（只需要约6GB显存）
python icl.py --model_name gpt2-xl

# 查看所有可用参数
python icl.py --help
```

这个模型下载更快（约1.5GB），运行也更快，适合用来测试环境是否正常。

---

## 📊 看懂输出结果

运行时，你会看到类似这样的输出：
```
0 0 0 0.0 0 0.0 0 0.0
10 45 68 0.125 38 0.089 8 0.156
20 92 138 0.142 78 0.095 17 0.168
...
```

**每列的含义**：
- 第1列：处理到第几个样本
- 第2-3列：邻域提示的成功次数和总次数
- 第4列：邻域提示的平均得分
- 第5列：改述提示的成功次数
- 第6列：改述提示的平均得分
- 第7列：原始提示的成功次数
- 第8列：原始提示的平均得分

数字越高说明效果越好！

---

## 🔥 常见问题快速解决

### 问题1：pip install 很慢或失败
**解决方案**：使用国内镜像
```bash
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### 问题2：CUDA out of memory（显存不足）
**解决方案**：使用更小的模型
```bash
# 最小模型（约6GB显存）
python icl.py --model_name gpt2-xl

# 中等模型（约16GB显存）
python icl.py --model_name EleutherAI/gpt-neo-1.3B
```
**模型大小对比**：
- `gpt2-xl`: 1.5GB模型，需要6GB显存
- `EleutherAI/gpt-neo-1.3B`: 2.6GB模型，需要16GB显存
- `EleutherAI/gpt-j-6B`: 12GB模型，需要24GB显存（默认）

### 问题3：找不到counterfact.json
**解决方案**：
- 确保文件在项目根目录（`/data/chenminghao/code/IKE/`）
- 检查文件名是否完全一致（注意大小写）

### 问题4：程序运行很慢
**这是正常的！** 因为：
- 语言模型计算量很大
- 需要处理2000个测试样本
- 每个样本都要进行多次预测
- 预计需要数小时完成

---

## 💡 小贴士

1. **第一次运行最慢**：因为要下载模型，之后就快了
2. **可以中断重跑**：虽然目前不支持断点续传，但可以随时Ctrl+C停止
3. **查看GPU使用情况**：可以另开一个终端运行`watch -n 1 nvidia-smi`实时查看
4. **节省时间**：如果只是想测试，可以修改代码只处理前100个样本

---

## 📞 需要帮助？

如果遇到问题：
1. 检查是否按照步骤操作
2. 查看完整的README.md文件
3. 检查错误信息的关键词，对照常见问题

祝你运行顺利！🎉

