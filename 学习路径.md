# 🎓 IKE 项目学习路径

这份文档为你提供一条清晰的学习路径，帮助你从零开始掌握这个项目。

---

## 📚 学习路线图

```
Level 1: 基础理解（1-2小时）
   ↓
Level 2: 运行项目（2-3小时）
   ↓
Level 3: 深入代码（3-5小时）
   ↓
Level 4: 实验改进（进阶）
```

---

## 🎯 Level 1: 基础理解（必读）

### 目标
了解项目是做什么的，为什么要做。

### 学习材料
1. ✅ 阅读 `README.md` 的"项目简介"部分
2. ✅ 理解三个核心概念

### 核心概念

#### 1️⃣ 什么是知识编辑？
**问题**：语言模型记住的知识可能会过时或错误
**例子**：
- 模型记住："Twitter 的CEO是 Jack Dorsey"
- 实际上现在是：Elon Musk

**传统解决方案**：重新训练模型（耗时、昂贵）
**本项目方案**：通过示例教会模型新知识（快速、便宜）

#### 2️⃣ 什么是上下文学习（ICL）？
**定义**：给模型看一些示例，让它通过模仿来完成任务

**简单类比**：
```
就像教小孩做数学题：

示例1: 1 + 1 = 2
示例2: 2 + 3 = 5
示例3: 4 + 5 = 9

现在做题: 6 + 7 = ?

小孩看了前面的例子，就知道应该把两个数加起来。
```

**在本项目中**：
```
示例1: Bill Gates 现在在 Apple 工作
      Q: Bill Gates 在哪工作？
      A: Apple

示例2: Steve Jobs 创办了 Google
      Q: Steve Jobs 创办了什么？
      A: Google

现在测试: Elon Musk 现在在 Microsoft 工作
        Q: Elon Musk 在哪工作？
        A: ?（期望模型回答：Microsoft）
```

#### 3️⃣ 为什么需要评估三个指标？

**1. 有效性（Efficacy）**
- **问题**：模型真的学会了吗？
- **测试**：直接问原始问题

**2. 泛化性（Generalization）**
- **问题**：换个说法还能答对吗？
- **测试**：用不同的问法问同一个问题
- **例子**：
  ```
  原始: "Elon Musk 在哪工作？"
  改述: "Elon Musk 的雇主是谁？"
  改述: "谁雇佣了 Elon Musk？"
  ```

**3. 局部性（Locality）**
- **问题**：学会新知识后，会不会忘记相关的旧知识？
- **测试**：问相关但不同的问题
- **例子**：
  ```
  新知识: "Elon Musk 在 Microsoft 工作"
  相关问题: "Tesla 是谁创办的？"
  期望: 模型仍然回答 "Elon Musk"（而不是被 Microsoft 干扰）
  ```

### ✅ 检查点
- [ ] 我理解了什么是知识编辑
- [ ] 我理解了什么是上下文学习
- [ ] 我理解了为什么需要三个评估指标

---

## 🚀 Level 2: 运行项目（实践）

### 目标
成功运行项目，看到实验结果。

### 步骤清单

#### Step 1: 环境检查
```bash
# 检查Python版本（需要3.7+）
python --version

# 检查GPU（需要NVIDIA显卡）
nvidia-smi
```

#### Step 2: 安装依赖
```bash
cd /data/chenminghao/code/IKE

# 安装所有依赖包
pip install -r requirements.txt

# 如果速度慢，使用国内镜像
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

#### Step 3: 准备数据
```bash
# 数据已经存在，检查一下
ls -lh counterfact.json

# 如果没有，下载
wget https://rome.baulab.info/data/dsets/counterfact.json
```

#### Step 4: 清理数据
```bash
python clean_paraphrase.py
```

**观察**：会看到大量输出，这是清理后的提示词

#### Step 5: 运行实验（快速测试）
```bash
# 使用小模型快速测试（推荐新手）
python icl.py --model_name gpt2-xl
```

**预期时间**：
- 第一次运行：30分钟到1小时（下载模型）
- 后续运行：每个样本约2-5秒

**预期输出**：
```
0 0 0 0.0 0 0.0 0 0.0
10 45 68 0.125 38 0.089 8 0.156
20 92 138 0.142 78 0.095 17 0.168
...
```

### 🎯 理解输出

每一行代表处理到第N个样本时的统计：
```
[样本数] [邻域成功] [邻域总数] [邻域得分] [改述成功] [改述得分] [原始成功] [原始得分]
```

**例子**：
```
10 45 68 0.125 38 0.089 8 0.156
```
意思是：
- 处理了10个样本
- 邻域提示：68次测试，成功45次，平均得分0.125
- 改述提示：成功38次，平均得分0.089
- 原始提示：成功8次，平均得分0.156

### ✅ 检查点
- [ ] 成功安装了所有依赖
- [ ] 成功运行了 clean_paraphrase.py
- [ ] 成功运行了 icl.py（至少看到输出）
- [ ] 理解了输出的含义

---

## 🔍 Level 3: 深入代码（核心）

### 目标
理解代码的核心逻辑，能够解释每个关键函数的作用。

### 3.1 数据结构理解

#### 打开 counterfact.json 观察数据
```bash
# 查看前50行
head -50 counterfact.json
```

**关键字段**：
```json
{
  "requested_rewrite": {
    "subject": "主语（人名/地名/机构名）",
    "prompt": "提示模板，包含 {}",
    "target_new": {"str": "新答案（反事实）"},
    "target_true": {"str": "真实答案"}
  },
  "paraphrase_prompts": ["改述1", "改述2", ...],
  "neighborhood_prompts": ["相关问题1", "相关问题2", ...]
}
```

**动手练习**：
1. 找一条完整的数据
2. 识别出：subject、prompt、target_new、target_true
3. 理解为什么叫"反事实"（counterfact）

### 3.2 核心函数解析

#### 🔥 最重要的函数：construct_icl_examples()

**位置**：`icl.py` 第31-52行

**作用**：构建上下文示例（这是整个项目的核心！）

**详细解析**：
```python
def construct_icl_examples(idx, demos):
    # order定义了示例的类型分布
    # 0 = 原始提示+新答案
    # 1 = 改述提示+新答案  
    # 2 = 邻域提示+旧答案
    order = [2, 1, 2, 0, 1, 2, 2, 0, 2, 2, ...]
    
    # 随机打乱，避免顺序偏差
    random.shuffle(order)
    
    icl_examples = []
    
    # 获取最相似的32个示例的索引
    demo_ids = corpus_idx[idx]
    demo_ids = demo_ids[:len(order)]
    
    # 对每个示例，根据order类型构建
    for demo_id, o in zip(demo_ids, order):
        line = demos[demo_id-2000]  # 从示例库中取
        
        new_fact = line['requested_rewrite']['prompt'].format(...)
        target_new = line['requested_rewrite']['target_new']['str']
        target_true = line['requested_rewrite']['target_true']['str']
        
        if o == 0:  # 类型0：原始提示+新答案
            icl_examples.append(
                f'New Fact: {new_fact} {target_new}\n'
                f'Prompt: {new_fact} {target_new}\n\n'
            )
        elif o == 1:  # 类型1：改述提示+新答案
            prompt = random.choice(line['paraphrase_prompts'])
            icl_examples.append(
                f'New Fact: {new_fact} {target_new}\n'
                f'Prompt: {prompt} {target_new}\n\n'
            )
        elif o == 2:  # 类型2：邻域提示+旧答案
            prompt = random.choice(line['neighborhood_prompts'])
            icl_examples.append(
                f'New Fact: {new_fact} {target_new}\n'
                f'Prompt: {prompt} {target_true}\n\n'
            )
    
    # 反转顺序（最相似的放最后，模型对最近示例更敏感）
    icl_examples.reverse()
    
    return icl_examples
```

**为什么要混合三种类型？**

想象你要教一个学生：
- **类型0**：告诉他标准答案
- **类型1**：换个说法，确保他真的理解
- **类型2**：给相关但不同的问题，确保他不会混淆

**动手练习**：
1. 在 `icl.py` 中找到这个函数
2. 添加一行 `print(icl_examples[0])`，看看示例长什么样
3. 运行代码，观察输出

#### 🔥 第二重要的函数：icl_lm_eval()

**位置**：`icl.py` 第55-76行

**作用**：评估模型对每个答案的偏好程度

**核心思想**：
```python
# 对每个候选答案（新答案、旧答案）
for target in targets:
    # 1. 构建完整输入：[示例] + [提示] + [答案]
    full_text = ''.join(icl_examples) + f'{x} {target}'
    
    # 2. 让模型计算这个序列的困惑度（perplexity）
    ppl = 模型计算困惑度(full_text)
    
    # 3. 困惑度越低 = 模型越确信
    ppls.append(ppl)

return ppls
```

**困惑度（Perplexity）的直观理解**：
- **低困惑度**：模型觉得"这个答案很正常"
- **高困惑度**：模型觉得"这个答案很奇怪"

**例子**：
```
问题: "太阳从哪里升起？"
答案A: "东方" → PPL = 1.2（低，模型很确信）
答案B: "西方" → PPL = 50.3（高，模型觉得奇怪）
```

**判断逻辑**：
```python
prob_new = 1 / ppl_new  # 新答案的概率
prob_old = 1 / ppl_old  # 旧答案的概率

if prob_new > prob_old:
    # 模型更倾向新答案，知识编辑成功！
    success_cnt += 1
```

### 3.3 主实验流程

**位置**：`icl.py` 第130-183行

**流程图**：
```
对每个测试样本（共2000个）：
  │
  ├─ 1. 构建32个上下文示例
  │    └─ 调用 construct_icl_examples()
  │
  ├─ 2. 测试原始提示（Efficacy）
  │    ├─ 提示: "Elon Musk works at"
  │    ├─ 候选: ["Microsoft"(新), "Tesla"(旧)]
  │    └─ 判断: 模型更倾向哪个？
  │
  ├─ 3. 测试改述提示（Generalization）
  │    ├─ 遍历所有改述
  │    ├─ 提示: "The employer of Elon Musk is"
  │    └─ 判断: 还能答对吗？
  │
  └─ 4. 测试邻域提示（Locality）
       ├─ 遍历所有邻域提示
       ├─ 提示: "Tesla was founded by"
       └─ 判断: 相关知识还对吗？
```

### ✅ 检查点
- [ ] 我理解了 counterfact.json 的数据结构
- [ ] 我理解了 construct_icl_examples() 的作用
- [ ] 我理解了 icl_lm_eval() 的作用
- [ ] 我理解了主实验的流程

---

## 🎨 Level 4: 实验改进（进阶）

### 目标
能够修改代码，进行自己的实验。

### 4.1 简单改进实验

#### 实验1: 改变示例数量
**假设**：使用更多示例效果会更好吗？

**修改**：
```python
# 在 construct_icl_examples() 中
# 原来：demo_ids = demo_ids[:len(order)]  # 32个
# 改为：demo_ids = demo_ids[:16]  # 只用16个

# 或者：demo_ids = demo_ids[:64]  # 用64个（注意token限制）
```

**观察**：对比成功率的变化

#### 实验2: 改变示例类型分布
**假设**：更多改述类型（type 1）能提高泛化性吗？

**修改**：
```python
# 原来：
order = [2, 1, 2, 0, 1, 2, 2, 0, 2, 2, 1, 0, ...]

# 改为（增加type 1的比例）：
order = [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 0, ...]
```

**观察**：泛化性指标是否提高

#### 实验3: 只测试前100个样本
**目的**：快速验证想法

**修改**：
```python
# 在主循环中
for i, line in enumerate(lines[:100]):  # 只测试前100个
    ...
```

### 4.2 分析实验

#### 实验4: 按关系类型分析
**问题**：不同类型的知识，编辑效果一样吗？

**修改**：
```python
# 创建一个字典记录每种关系的成功率
relation_stats = {}

for i, line in enumerate(lines):
    relation = line['requested_rewrite']['relation_id']
    
    if relation not in relation_stats:
        relation_stats[relation] = {'success': 0, 'total': 0}
    
    # ... 测试逻辑 ...
    
    if 成功:
        relation_stats[relation]['success'] += 1
    relation_stats[relation]['total'] += 1

# 最后输出每种关系的成功率
for relation, stats in relation_stats.items():
    print(f"{relation}: {stats['success']}/{stats['total']}")
```

### 4.3 可视化改进

#### 实验5: 保存详细结果
```python
import json

results = []

for i, line in enumerate(lines):
    # ... 实验逻辑 ...
    
    results.append({
        'case_id': line.get('case_id'),
        'subject': subject,
        'efficacy': orig_success,
        'generalization': para_success_rate,
        'locality': neighbor_success_rate
    })

# 保存结果
with open('detailed_results.json', 'w') as f:
    json.dump(results, f, indent=2)
```

#### 实验6: 绘制成功率曲线
```python
import matplotlib.pyplot as plt

success_rates = []  # 记录每10个样本的成功率

# 在主循环中
if i % 10 == 0 and i > 0:
    success_rate = success_cnt / total_cnt
    success_rates.append(success_rate)

# 绘图
plt.plot(success_rates)
plt.xlabel('Sample Index (×10)')
plt.ylabel('Success Rate')
plt.title('Locality Success Rate Over Samples')
plt.savefig('success_rate.png')
```

### ✅ 检查点
- [ ] 我能修改代码进行简单实验
- [ ] 我能分析实验结果
- [ ] 我能提出自己的研究问题

---

## 🎯 推荐学习顺序

### 第1天：理解基础（2-3小时）
- [ ] 阅读 Level 1 全部内容
- [ ] 阅读 README.md
- [ ] 观察 counterfact.json 数据

### 第2天：运行实验（3-4小时）
- [ ] 完成 Level 2 的所有步骤
- [ ] 成功运行一次完整实验
- [ ] 理解输出结果

### 第3天：深入代码（4-5小时）
- [ ] 阅读 `代码导读.md`
- [ ] 逐行阅读 `icl.py`
- [ ] 在关键位置添加 print 语句观察

### 第4天：尝试改进（进阶）
- [ ] 尝试 Level 4 的简单实验
- [ ] 提出自己的研究问题
- [ ] 修改代码验证想法

---

## 📚 辅助资源

### 项目文档
- `README.md` - 完整使用指南
- `快速开始指南.md` - 简化的运行步骤
- `代码导读.md` - 详细的代码解析
- `学习路径.md` - 本文档

### 推荐阅读顺序
1. README.md（快速了解）
2. 快速开始指南.md（开始运行）
3. 学习路径.md（系统学习，Level 1 → Level 4）
4. 代码导读.md（深入理解，作为参考手册）

### 外部资源
- [Transformer模型介绍](https://jalammar.github.io/illustrated-transformer/)
- [GPT模型原理](https://jalammar.github.io/illustrated-gpt2/)
- [In-Context Learning论文](https://arxiv.org/abs/2005.14165)（GPT-3论文）

---

## 🆘 遇到困难？

### 概念不理解
→ 回到 Level 1，重新阅读核心概念

### 代码看不懂
→ 阅读 `代码导读.md`，逐行解析

### 运行出错
→ 查看 README.md 的"常见问题"部分

### 想深入研究
→ 进入 Level 4，设计自己的实验

---

## 🎉 学习建议

1. **不要跳步**：按照 Level 1 → 2 → 3 → 4 的顺序学习
2. **多动手**：光看不练假把式，一定要运行代码
3. **多提问**：不懂的地方及时标记，寻求帮助
4. **做笔记**：记录自己的理解和发现
5. **做实验**：尝试修改代码，观察结果变化

---

## ✅ 最终检查清单

完成学习后，你应该能够：

### 基础理解
- [ ] 解释什么是知识编辑
- [ ] 解释什么是上下文学习
- [ ] 解释三个评估指标的含义

### 代码理解
- [ ] 说出每个文件的作用
- [ ] 解释 construct_icl_examples() 的逻辑
- [ ] 解释 icl_lm_eval() 的原理
- [ ] 画出主实验流程图

### 实践能力
- [ ] 独立运行完整实验
- [ ] 修改参数重新实验
- [ ] 分析实验结果
- [ ] 提出改进想法

---

祝你学习愉快！🎓

